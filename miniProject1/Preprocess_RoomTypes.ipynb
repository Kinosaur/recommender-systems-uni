{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eccaea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed data for 'roomtype' (selected columns) to 'Group4_Part1_preprocessed_roomtype.csv'\n",
      "Saved minimal mapping for 'roomtype' to 'Group4_Part1_id_tokens_roomtype.csv'\n",
      "\n",
      "Preprocessing for 'roomtype' column completed.\n",
      "\n",
      "First 5 rows of the preprocessed data (with selected columns):\n",
      "   itemid                     roomtype          roomtype_tokens  \\\n",
      "0       1          Comfort Double Room        {comfort, double}   \n",
      "1       2  Classic Double or Twin Room  {twin, classic, double}   \n",
      "2       3         Superior Double Room       {superior, double}   \n",
      "3       4                        Suite                  {suite}   \n",
      "4       5  Classic Double or Twin Room  {twin, classic, double}   \n",
      "\n",
      "  roomtype_tokens_filtered  roomtype_tokens_str  \n",
      "0        {comfort, double}       comfort_double  \n",
      "1  {twin, classic, double}  classic_double_twin  \n",
      "2       {superior, double}      double_superior  \n",
      "3                  {suite}                suite  \n",
      "4  {twin, classic, double}  classic_double_twin  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('HOTEL_OUTDATASET.CSV')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'HOTEL_DATASET.CSV' not found. Please make sure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 1: Preprocessing for 'roomtype' column ---\n",
    "def preprocess_roomtype(roomtype_str):\n",
    "    if pd.isna(roomtype_str):\n",
    "        return set() # Return an empty set for missing values\n",
    "    # 2. Lowercase\n",
    "    tokens = str(roomtype_str).lower()\n",
    "    # 3. Replace spaces with underscores\n",
    "    tokens = tokens.replace(' ', '_')\n",
    "    # 4. Remove leading/trailing punctuation and split into potential tokens\n",
    "    potential_tokens = re.split(r'[;,/_\\-]+', tokens)\n",
    "\n",
    "    processed_tokens = set()\n",
    "    for token in potential_tokens:\n",
    "        cleaned_token = re.sub(r'^[^\\w]+|[^\\w]+$', '', token)\n",
    "        if cleaned_token == 'room':\n",
    "            pass\n",
    "\n",
    "        elif cleaned_token == 'double':\n",
    "            processed_tokens.add('double')\n",
    "\n",
    "        elif cleaned_token and len(cleaned_token) > 1 and cleaned_token not in ['with', 'only', 'use', 'or', 'of']:\n",
    "            processed_tokens.add(cleaned_token)\n",
    "\n",
    "    final_tokens = set()\n",
    "    has_meaningful_token = False\n",
    "    for token in processed_tokens:\n",
    "        if token not in ['with', 'only']: # Re-apply filtering for safety\n",
    "            if token == 'room':\n",
    "                if len(processed_tokens) == 1:\n",
    "                    final_tokens.add('single')\n",
    "                    has_meaningful_token = True\n",
    "            elif token == 'double':\n",
    "                final_tokens.add('double')\n",
    "                has_meaningful_token = True\n",
    "            else:\n",
    "                final_tokens.add(token)\n",
    "                has_meaningful_token = True\n",
    "\n",
    "    if not has_meaningful_token and any(t.lower() == 'room' for t in str(roomtype_str).lower().split()):\n",
    "         final_tokens.add('single')\n",
    "    return final_tokens\n",
    "\n",
    "df['roomtype_tokens'] = df['roomtype'].apply(preprocess_roomtype)\n",
    "\n",
    "# --- Step 2: Common Token Filtering (for roomtype tokens) ---\n",
    "token_counts = {}\n",
    "for tokens_set in df['roomtype_tokens']:\n",
    "    for token in tokens_set:\n",
    "        token_counts[token] = token_counts.get(token, 0) + 1\n",
    "\n",
    "total_hotels = len(df)\n",
    "\n",
    "common_token_threshold = 0.70\n",
    "tokens_to_remove = {token for token, count in token_counts.items() if count / total_hotels >= common_token_threshold}\n",
    "\n",
    "df['roomtype_tokens_filtered'] = df['roomtype_tokens'].apply(\n",
    "    lambda tokens_set: {token for token in tokens_set if token not in tokens_to_remove}\n",
    ")\n",
    "\n",
    "# --- Step 3: Output for Step 1 (for roomtype) ---\n",
    "df['roomtype_tokens_str'] = df['roomtype_tokens_filtered'].apply(lambda x: '_'.join(sorted(list(x))))\n",
    "\n",
    "output_columns = ['itemid', 'hotelid', 'roomtype', 'roomtype_tokens', 'roomtype_tokens_filtered', 'roomtype_tokens_str']\n",
    "df_output = df[output_columns]\n",
    "\n",
    "df_output.to_csv('Group4_Part1_preprocessed_roomtype.csv', index=False)\n",
    "print(\"Saved preprocessed data for 'roomtype' (selected columns) to 'Group4_Part1_preprocessed_roomtype.csv'\")\n",
    "\n",
    "df_output_mapping = df_output[['itemid', 'roomtype_tokens_str']]\n",
    "df_output_mapping = df_output_mapping.rename(columns={'roomtype_tokens_str': 'tokens'})\n",
    "df_output_mapping.to_csv('Group4_Part1_id_tokens_roomtype.csv', index=False)\n",
    "\n",
    "print(\"Saved minimal mapping for 'roomtype' to 'Group4_Part1_id_tokens_roomtype.csv'\")\n",
    "print(\"\\nPreprocessing for 'roomtype' column completed.\")\n",
    "print(\"\\nFirst 5 rows of the preprocessed data (with selected columns):\")\n",
    "print(df_output[['itemid', 'roomtype', 'roomtype_tokens', 'roomtype_tokens_filtered', 'roomtype_tokens_str']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f042c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed data for 'roomtype' (selected columns) to 'Group4_Part1_preprocessed_roomtype.csv'\n",
      "Saved minimal mapping for 'roomtype' to 'Group4_Part1_id_tokens_roomtype.csv'\n",
      "\n",
      "Preprocessing for 'roomtype' column completed.\n",
      "\n",
      "First 5 rows of the preprocessed data (with selected columns):\n",
      "   itemid                     roomtype roomtype_tokens  \\\n",
      "0       1          Comfort Double Room        {double}   \n",
      "1       2  Classic Double or Twin Room  {double, twin}   \n",
      "2       3         Superior Double Room        {double}   \n",
      "3       4                        Suite         {suite}   \n",
      "4       5  Classic Double or Twin Room  {double, twin}   \n",
      "\n",
      "  roomtype_tokens_filtered roomtype_tokens_str  \n",
      "0                 {double}              double  \n",
      "1           {double, twin}         double_twin  \n",
      "2                 {double}              double  \n",
      "3                  {suite}               suite  \n",
      "4           {double, twin}         double_twin  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('HOTEL_OUTDATASET.CSV')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'HOTEL_DATASET.CSV' not found. Please make sure the file is in the correct directory.\")\n",
    "    exit()\n",
    "\n",
    "# --- Step 1: Preprocessing for 'roomtype' column ---\n",
    "\n",
    "def preprocess_roomtype(roomtype_str):\n",
    "    if pd.isna(roomtype_str):\n",
    "        return set() # Return an empty set for missing values\n",
    "\n",
    "    # 2. Lowercase\n",
    "    tokens = str(roomtype_str).lower()\n",
    "\n",
    "    # 3. Replace spaces with underscores\n",
    "    tokens = tokens.replace(' ', '_')\n",
    "\n",
    "    # 4. Remove leading/trailing punctuation and split into potential tokens\n",
    "    potential_tokens = re.split(r'[;,/_\\-]+', tokens)\n",
    "\n",
    "    # Define stop words to remove (common words, qualifiers, and view-related terms)\n",
    "    stop_words = {\n",
    "        'with', 'only', 'use', 'or', 'of', 'room', 'deluxe', 'superior', 'classic', 'comfort', 'balcony',\n",
    "        'city', 'garden', 'mountain', 'street', 'ocean', 'lake', 'view', 'terraced'\n",
    "    } # Added view-related terms\n",
    "\n",
    "    processed_tokens = set()\n",
    "    has_double = False\n",
    "    has_twin = False\n",
    "    has_single = False\n",
    "    other_tokens = set()\n",
    "\n",
    "    for token in potential_tokens:\n",
    "        cleaned_token = re.sub(r'^[^\\w]+|[^\\w]+$', '', token)\n",
    "\n",
    "        if cleaned_token and len(cleaned_token) > 1:\n",
    "            if cleaned_token == 'double':\n",
    "                has_double = True\n",
    "            elif cleaned_token == 'twin':\n",
    "                has_twin = True\n",
    "            elif cleaned_token == 'single':\n",
    "                has_single = True\n",
    "            elif cleaned_token not in stop_words:\n",
    "                other_tokens.add(cleaned_token)\n",
    "\n",
    "    # Now, construct the final set based on the presence of 'double'\n",
    "    final_tokens = set()\n",
    "    if has_double:\n",
    "        final_tokens.add('double')\n",
    "        if has_twin:\n",
    "            final_tokens.add('twin')\n",
    "    else: # No \"double\" found\n",
    "        if has_single:\n",
    "            final_tokens.add('single')\n",
    "        if has_twin:\n",
    "            final_tokens.add('twin')\n",
    "        # Add any other meaningful tokens that are not stop words\n",
    "        for token in other_tokens:\n",
    "            final_tokens.add(token)\n",
    "\n",
    "    # Special case: If after all this, the set is empty and the original string contained \"room\",\n",
    "    # treat it as \"single\".\n",
    "    if not final_tokens and any(t.lower() == 'room' for t in str(roomtype_str).lower().split()):\n",
    "         final_tokens.add('single')\n",
    "    elif not final_tokens and not has_double and not has_single and not has_twin and other_tokens:\n",
    "        # If no specific type was identified, but there were other tokens, add them\n",
    "        final_tokens.update(other_tokens)\n",
    "\n",
    "    return final_tokens\n",
    "\n",
    "# Apply the preprocessing function to the 'roomtype' column\n",
    "df['roomtype_tokens'] = df['roomtype'].apply(preprocess_roomtype)\n",
    "\n",
    "# --- Step 3: Common Token Filtering (for roomtype tokens) ---\n",
    "\n",
    "# Calculate token frequencies\n",
    "token_counts = {}\n",
    "for tokens_set in df['roomtype_tokens']:\n",
    "    for token in tokens_set:\n",
    "        token_counts[token] = token_counts.get(token, 0) + 1\n",
    "\n",
    "# Determine the total number of hotels\n",
    "total_hotels = len(df)\n",
    "\n",
    "# Filter out common tokens (appearing in >= 70% of hotels)\n",
    "common_token_threshold = 0.70\n",
    "tokens_to_remove = {token for token, count in token_counts.items() if count / total_hotels >= common_token_threshold}\n",
    "\n",
    "# Remove common tokens from the token sets\n",
    "df['roomtype_tokens_filtered'] = df['roomtype_tokens'].apply(\n",
    "    lambda tokens_set: {token for token in tokens_set if token not in tokens_to_remove}\n",
    ")\n",
    "\n",
    "# --- Step 5: Output for Step 1 (for roomtype) ---\n",
    "\n",
    "# Create the 'roomtype_tokens_str' column\n",
    "df['roomtype_tokens_str'] = df['roomtype_tokens_filtered'].apply(lambda x: '_'.join(sorted(list(x))))\n",
    "\n",
    "# Select only the specified columns for the output file\n",
    "output_columns = ['itemid', 'hotelid', 'roomtype', 'roomtype_tokens', 'roomtype_tokens_filtered', 'roomtype_tokens_str']\n",
    "df_output = df[output_columns]\n",
    "\n",
    "df_output.to_csv('Group4_Part1_preprocessed_roomtype.csv', index=False)\n",
    "print(\"Saved preprocessed data for 'roomtype' (selected columns) to 'Group4_Part1_preprocessed_roomtype.csv'\")\n",
    "\n",
    "# Create the minimal mapping (itemid, token_str)\n",
    "df_output_mapping = df_output[['itemid', 'roomtype_tokens_str']]\n",
    "# Rename the token column to 'tokens' as per the example\n",
    "df_output_mapping = df_output_mapping.rename(columns={'roomtype_tokens_str': 'tokens'})\n",
    "df_output_mapping.to_csv('Group4_Part1_id_tokens_roomtype.csv', index=False)\n",
    "print(\"Saved minimal mapping for 'roomtype' to 'Group4_Part1_id_tokens_roomtype.csv'\")\n",
    "\n",
    "print(\"\\nPreprocessing for 'roomtype' column completed.\")\n",
    "print(\"\\nFirst 5 rows of the preprocessed data (with selected columns):\")\n",
    "print(df_output[['itemid', 'roomtype', 'roomtype_tokens', 'roomtype_tokens_filtered', 'roomtype_tokens_str']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
